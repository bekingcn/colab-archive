{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bekingcn/colab-archive/blob/main/build_llm_powered_pipelines_with_haystack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About Haystack\n",
        "\n",
        "Haystack is the open source Python framework by deepset for building custom apps with large language models (LLMs). It lets you quickly try out the latest models in natural language processing (NLP) while being flexible and easy to use. Our inspiring community of users and builders has helped shape Haystack into what it is today: a complete framework for building production-ready NLP apps.\n",
        "\n",
        "![](https://haystack.deepset.ai/images/model_providers_hu0cc9bf8102b4d45e75d89acd8a0ddbf4_163613_800x0_resize_q80_box_3.png)\n",
        "\n",
        "### Some examples of what you can build include:\n",
        "\n",
        "* Semantic search on a large collection of documents in any language\n",
        "* Generative question answering on a knowledge base containing mixed types of information: images, text, and tables.\n",
        "* Natural language chatbots powered by cutting-edge generative models like GPT-4\n",
        "* An LLM-based Haystack Agent capable of resolving complex queries\n",
        "* Information extraction from documents to populate your database or build a knowledge graph\n",
        "\n",
        "## Key concetps:\n",
        "\n",
        "### üîß Components\n",
        "Haystack offers various components, each performing different kinds of tasks. You can see the whole variety in the PIPELINE COMPONENTS section in the left-side navigation. These are often powered by the latest Large Language Models (LLMs) and transformer models. Code-wise, they are Python classes with methods you can directly call. Most commonly, all you need to do is initialize the component with the required parameters and then run it with a run() method.\n",
        "\n",
        "\n",
        "### ‚öôÔ∏è Generators\n",
        "Generators are responsible for generating text responses after you give them a prompt. They are specific for each LLM technology (OpenAI, Cohere, local models, and others). There are two types of Generators: chat and non-chat:\n",
        "\n",
        "The chat ones enable chat completion and are designed for conversational contexts. It expects a list of messages to interact with the user.\n",
        "The non-chat Generators use LLMs for simpler text generation (for example, translating or summarizing text).\n",
        "\n",
        "### üîé Retrievers\n",
        "Retrievers go through all the Documents in a Document Store, select the ones that match the user query, and pass it on to the next component. There are various Retrievers that are customized for specific Document Stores. This means that they can handle specific requirements for each database using customized parameters.\n",
        "\n",
        "For example, for Elasticsearch Document Store, you will find both the Document Store and Retriever packages in its GitHub repo.\n",
        "\n",
        "### üìñ Document Stores\n",
        "Document Store is an object that stores your Documents in Haystack, like an interface to a storage database. It uses specific functions like write_documents() or delete_documents() to work with data. Various components have access to the Document Store and can interact with it by, for example, reading or writing Documents.\n",
        "\n",
        "If you are working with more complex Pipelines in Haystack, you can use a DocumentWriter component to write data into Document Stores for you.\n",
        "\n",
        "### üëì Data Classes\n",
        "You can use different data classes in Haystack to carry the data through the system. The data classes are mostly likely to appear as inputs or outputs of your Pipelines.\n",
        "\n",
        "Document class contains information to be carried through the Pipeline. It can be text, metadata, tables, or binary data. Documents can be written into Document Stores but also written and read by other components.\n",
        "\n",
        "Answer class holds not only the answer generated in a Pipeline but also the originating query and metadata.\n",
        "\n",
        "### üõ†Ô∏è Pipelines\n",
        "Finally, you can combine various components, Document Stores, and integrations into Pipelines to create powerful and customizable systems. It is a highly flexible system that allows you to have simultaneous flows, standalone components, loops, and other types of connections. You can have the preprocessing, indexing, and querying steps all in one Pipeline, or you can split them up according to your needs.\n",
        "\n",
        "If you want to re-use Pipelines, you can save them into a convenient format (YAML, TOML, and more) on a disk or share them around using the serialization process.\n",
        "\n",
        "## Sample use cases with Colab notebooks\n",
        "\n",
        "1. [Build an LLM pipeline from a collection of URLs](https://colab.research.google.com/drive/1R0_zrFrVW0awTS7LbHKlgFMCVYQndf4L?usp=sharing) - in this notebook you will learn how to build an LLM-powered pipeline that takes as input a URL, and enables an LLM to answer questions about it.\n",
        "2. [Add a ranker to the LLM pipeline](https://colab.research.google.com/drive/1nEoYiZpIw4QJK7b7iN13PHrrp7C-eftS) - this can be useful if you'd like to rank your Documents.\n",
        "3. [Build an indexing and retriever pipeline that can parse through document metadata](https://colab.research.google.com/drive/1h20hE2kVmSoKF0TGd2fz6z5E9IRULGd6?usp=sharing)\n",
        "4. [Create a pipeline with branches](https://colab.research.google.com/drive/1JDFZAUMqQtbWuZsVGIqEj-yaKmv2Z3JX?usp=sharing)  - in this case the pipeline will route documents with different languages to a document store for the corresponding language\n",
        "5. [Use document metadata to filter documents within your pipeline](https://colab.research.google.com/drive/1JzO8lkrb4DtnkPgKnaZkngZeHcfAWQQ5?usp=sharing)\n",
        "6. [Build a pipeline that can process PDF, txt and Markdown files and populates a document store through an indexing pipeline](https://colab.research.google.com/drive/1C_TccgpzWw2Nd7Qy3LeyvqFcnNJJNtWZ?usp=sharing)\n",
        "7. [Build a conditional pipeline](https://colab.research.google.com/drive/1DCYeoEl6I1uFErzNlcIslXqOPVWA4uTQ?usp=sharing) - if the answer is not on the document store, perform a web search using the serper API.\n",
        "8. [Build and incorporate custom-made components](https://colab.research.google.com/drive/1jL087DiDF6qYOI0WazACbUWzsuEKDv8b#scrollTo=GubHsUHRmh9j)\n",
        "9. [Build an LLM-powered pipeline for audio files using the Whisper API component](https://colab.research.google.com/drive/1l3xmy1Vs99YzTKnJk92zMjOSBqol0RJF?usp=sharing)\n",
        "10. [Beyond Python pipelines](https://colab.research.google.com/drive/13uRLk_pEFkHUNaDh2clzfociaJTWZMnc?usp=sharing) - serialize your Haystack pipelines into YAML format."
      ],
      "metadata": {
        "id": "OgqVEbFbeaPW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BnyqNBTeS5Q"
      },
      "outputs": [],
      "source": []
    }
  ]
}