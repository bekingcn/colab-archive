{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bekingcn/colab-archive/blob/main/YT_Video_Analyzer_Python_Gemini_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video Analyzer Python Gemini 2.0"
      ],
      "metadata": {
        "id": "Mu12ZMEaXApC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UWhMLLhunvD",
        "outputId": "87fcbea6-0a80-4e75-df23-f5666b2aa722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.9/111.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "ZNuPc4aH86if"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "S6pybEI0usET"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "O6eGafmO_gL-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.0-flash-exp\" # @param [\"gemini-1.5-flash-8b\",\"gemini-1.5-flash-002\",\"gemini-1.5-pro-002\",\"gemini-2.0-flash-exp\"] {\"allow-input\":true}"
      ],
      "metadata": {
        "id": "25z6D0tm-_to"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload our video"
      ],
      "metadata": {
        "id": "c9RgfbLW9aI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the file to be uploaded\n",
        "import pathlib\n",
        "\n",
        "img_path = pathlib.Path('/content/CAP Theorem Simplified.mp4')"
      ],
      "metadata": {
        "id": "bArbrhCA9ccB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the file using the API\n",
        "file_upload = client.files.upload(path=img_path)"
      ],
      "metadata": {
        "id": "p-Hd8Ztk-T2w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_upload"
      ],
      "metadata": {
        "id": "vR7hbKMR_Gel",
        "outputId": "2d5a33e9-a01e-4be0-b8ab-60439aa4498f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "File(name='files/74z84n40gxn8', display_name=None, mime_type='video/mp4', size_bytes=8988395, create_time=datetime.datetime(2024, 12, 19, 8, 58, 21, 951676, tzinfo=TzInfo(UTC)), expiration_time=datetime.datetime(2024, 12, 21, 8, 58, 21, 939978, tzinfo=TzInfo(UTC)), update_time=datetime.datetime(2024, 12, 19, 8, 58, 21, 951676, tzinfo=TzInfo(UTC)), sha256_hash=b'86de40dcdfc071b5d2a053f6444886fd4400a33949c0e1d267a326a7962c1c96', uri='https://generativelanguage.googleapis.com/v1beta/files/74z84n40gxn8', state='PROCESSING', video_metadata=None, error=None)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_upload.state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BpcdeRx25dHA",
        "outputId": "ac78fae9-c433-4a03-ef50-3c836c26cd74"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PROCESSING'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eEk4P3fK_OcJ",
        "outputId": "f9950a1d-0fa1-42eb-ed1f-dbf79f0a9131",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/74z84n40gxn8\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Prepare the file to be uploaded\n",
        "while file_upload.state == \"PROCESSING\":\n",
        "    print('Waiting for video to be processed.')\n",
        "    time.sleep(10)\n",
        "    file_upload = client.files.get(name=file_upload.name)\n",
        "\n",
        "if file_upload.state == \"FAILED\":\n",
        "  raise ValueError(file_upload.state)\n",
        "print(f'Video processing complete: ' + file_upload.uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMz9GIuvAiCO",
        "outputId": "bbf8ee1a-3df8-4f87-f1ad-51fdbb7c2153",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACTIVE\n"
          ]
        }
      ],
      "source": [
        "print(file_upload.state)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Calling a prompt on the video"
      ],
      "metadata": {
        "id": "7zPCuudP8NK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"When given a video and a query, call the relevant function only once with the appropriate timecodes and text for the video\""
      ],
      "metadata": {
        "id": "dAmrIYI7-d25"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_PROMPT = \"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object sent to set_timecodes with the timecode of the caption in the video.\""
      ],
      "metadata": {
        "id": "A0zpRFCI-weC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_PROMPT = \"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object with the timecode of the caption in the video.\""
      ],
      "metadata": {
        "id": "7yb7zdcQ-ibk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NlJ9NwRGT6d1",
        "outputId": "74ca7eef-87a1-40a2-fa7f-b3a24dfc291c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n[\n  {\n    \"timecode\": \"00:00\",\n    \"text\": \"The video begins with a dark background and a network of green dots connected by lines. The text \\\"ByteByteGo.com\\\" appears in green, followed by \\\"System Design\\\" in white. Below this, two book covers are shown, both titled \\\"SYSTEM DESIGN INTERVIEW\\\", with \\\"VOLUME 1\\\" on the left and \\\"VOLUME 2\\\" on the right. A green logo is in the center, and the text \\\"ByteByteGo Newsletter blog.bytebytego.com\\\" is below the logo.\"\n  },\n  {\n    \"timecode\": \"00:04\",\n    \"text\": \"The text \\\"System Design Video Series\\\" appears above the book covers and logo. The text \\\"CAP Theo\\\" appears in the center of the screen.\"\n  },\n  {\n    \"timecode\": \"00:06\",\n    \"text\": \"The text \\\"CAP Theorem\\\" appears in the center of the screen. A man with glasses is shown in a small box in the lower right corner.\"\n  },\n  {\n    \"timecode\": \"00:07\",\n    \"text\": \"The man in the box speaks, \\\"What is CAP theorem? How useful is it to system design? Let's take a look.\\\"\"\n  },\n  {\n    \"timecode\": \"00:12\",\n    \"text\": \"The man continues, \\\"The CAP theorem is a concept in computer science that explains the trade-offs between consistency, availability, and partition tolerance in distributed systems.\\\"\"\n  },\n  {\n    \"timecode\": \"00:22\",\n    \"text\": \"The man continues, \\\"Consistency refers to the property of a system where all nodes have a consistent view of the data. It means all clients see the same data at the same time, no matter which node they connect to.\\\"\"\n  },\n  {\n    \"timecode\": \"00:35\",\n    \"text\": \"The man continues, \\\"Availability refers to the ability of a system to respond to requests from users at all times.\\\"\"\n  },\n  {\n    \"timecode\": \"00:42\",\n    \"text\": \"The man continues, \\\"Partition tolerance refers to the ability of a system to continue operating even if there is a network partition.\\\"\"\n  },\n  {\n    \"timecode\": \"00:50\",\n    \"text\": \"The man continues, \\\"But what is a network partition?\\\"\"\n  },\n  {\n    \"timecode\": \"00:51\",\n    \"text\": \"The man continues, \\\"A network partition happens when nodes in a distributed system are unable to communicate with each other due to network failures.\\\"\"\n  },\n  {\n    \"timecode\": \"01:01\",\n    \"text\": \"The man continues, \\\"When there's a network partition, a system must choose between consistency and availability.\\\"\"\n  },\n  {\n    \"timecode\": \"01:07\",\n    \"text\": \"The man continues, \\\"If the system prioritizes consistency, it may become unavailable until the partition is resolved.\\\"\"\n  },\n  {\n    \"timecode\": \"01:14\",\n    \"text\": \"The man continues, \\\"If the system prioritizes availability, it may allow updates to the data. This could result in data inconsistencies until the partition is resolved.\\\"\"\n  },\n  {\n    \"timecode\": \"01:23\",\n    \"text\": \"The man continues, \\\"Now let's go through a concrete example.\\\"\"\n  },\n  {\n    \"timecode\": \"01:25\",\n    \"text\": \"The man continues, \\\"Let's say we have a tiny bank with two ATMs connected over the network.\\\"\"\n  },\n  {\n    \"timecode\": \"01:31\",\n    \"text\": \"The man continues, \\\"The ATMs support three operations: deposit, withdrawal, and check balance. No matter what happens, the balance should never go below zero.\\\"\"\n  },\n  {\n    \"timecode\": \"01:41\",\n    \"text\": \"The man continues, \\\"There is no central database in this bank to keep the account balance. It is stored on both ATMs.\\\"\"\n  },\n  {\n    \"timecode\": \"01:48\",\n    \"text\": \"The man continues, \\\"When a customer uses an ATM, the balance is updated on both ATMs over the network. This ensures that the ATMs have a consistent view of the account balance.\\\"\"\n  },\n  {\n    \"timecode\": \"01:58\",\n    \"text\": \"The man continues, \\\"If there's a network partition and ATMs are unable to communicate with each other, the system must choose between consistency and availability.\\\"\"\n  },\n  {\n    \"timecode\": \"02:07\",\n    \"text\": \"The man continues, \\\"If the bank prioritizes consistency, the ATM may refuse to process deposits or withdrawals until the partition is resolved. This ensures that the balance remains consistent, but the system is unavailable to customers.\\\"\"\n  },\n  {\n    \"timecode\": \"02:22\",\n    \"text\": \"The man continues, \\\"If the bank prioritizes availability, the ATM may allow deposits and withdrawals to occur, but the balance may become inconsistent until the partition is resolved.\\\"\"\n  },\n  {\n    \"timecode\": \"02:33\",\n    \"text\": \"The man continues, \\\"When there's a network partition, the customer could withdraw their entire balance from both ATMs. When the network comes back online, the inconsistency is resolved, and now the balance is negative. That is not good.\\\"\"\n  },\n  {\n    \"timecode\": \"02:48\",\n    \"text\": \"The man continues, \\\"Now let's go through another example and see how a social media platform could apply the CAP theorem.\\\"\"\n  },\n  {\n    \"timecode\": \"02:54\",\n    \"text\": \"The man continues, \\\"During a network partition, if two users are commenting on the same post at the same time, one user's comment may not be visible to the other user until the partition is resolved.\\\"\"\n  },\n  {\n    \"timecode\": \"03:06\",\n    \"text\": \"The man continues, \\\"Alternatively, if the platform prioritizes consistency, the commenting feature may be unavailable to users until the partition is resolved.\\\"\"\n  },\n  {\n    \"timecode\": \"03:16\",\n    \"text\": \"The man continues, \\\"For a social network, it is often acceptable to prioritize availability at the cost of users seeing slightly different views some of the time.\\\"\"\n  },\n  {\n    \"timecode\": \"03:25\",\n    \"text\": \"The man continues, \\\"The CAP theorem may sound very simple, but the real world is messy. As with many things in software engineering, this is all about trade-offs, and the choices are not always so black and white.\\\"\"\n  },\n  {\n    \"timecode\": \"03:37\",\n    \"text\": \"The man continues, \\\"The CAP theorem assumes 100% availability or 100% consistency. In the real world, there are degrees of consistency and availability that distributed system designers must carefully consider.\\\"\"\n  },\n  {\n    \"timecode\": \"03:50\",\n    \"text\": \"The man continues, \\\"This is where the simplistic model of the CAP theorem could be misleading.\\\"\"\n  },\n  {\n    \"timecode\": \"03:55\",\n    \"text\": \"The man continues, \\\"Now back to the bank example. During a network partition, the ATM could allow only balance inquiries to be processed while deposits and withdrawals are blocked.\\\"\"\n  },\n  {\n    \"timecode\": \"04:07\",\n    \"text\": \"The man continues, \\\"Alternatively, the bank could implement a hybrid approach. For example, the ATM could allow balance inquiries and small withdrawals to be processed during a partition, but block large withdrawals and or deposits until the partition is resolved.\\\"\"\n  },\n  {\n    \"timecode\": \"04:21\",\n    \"text\": \"The man continues, \\\"It is worth noting that in the real world, reconciliation after a network partition could get very messy. The bank example above is simple to reconcile.\\\"\"\n  },\n  {\n    \"timecode\": \"04:31\",\n    \"text\": \"The man continues, \\\"In real life, the data structures involved could be complex and challenging to reconcile. A good example of a complex data structure is Google Docs. Resolving conflicting updates could be tricky.\\\"\"\n  },\n  {\n    \"timecode\": \"04:45\",\n    \"text\": \"The man continues, \\\"So is the CAP theorem useful? Yes, it is a useful tool to help us think through the high-level trade-offs to consider when there's a network partition.\\\"\"\n  },\n  {\n    \"timecode\": \"04:54\",\n    \"text\": \"The man continues, \\\"This is a good starting point, but it does not provide a complete picture of the trade-offs to consider when designing a well-rounded distributed system.\\\"\"\n  },\n  {\n    \"timecode\": \"05:03\",\n    \"text\": \"The man continues, \\\"Specifically, when the system is operating normally without a network failure, which is most of the time, there's an entire set of interesting trade-offs to consider between latency and consistency. This is covered by the PACELC theorem, which we should cover in another video.\\\"\"\n  },\n  {\n    \"timecode\": \"05:21\",\n    \"text\": \"The man continues, \\\"If you'd like to learn more about system design, check out our books and weekly newsletter. Please subscribe if you learned something new. Thank you so much, and we'll see you next time.\\\"\"\n  }\n]\n```"
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=file_upload.uri,\n",
        "                    mime_type=file_upload.mime_type),\n",
        "                ]),\n",
        "        USER_PROMPT,\n",
        "    ],\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=SYSTEM_PROMPT,\n",
        "        temperature=0.0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add in the Function Calls to get back the data in a way we expect it"
      ],
      "metadata": {
        "id": "Y0DjyUkb_GCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_timecodes = types.FunctionDeclaration(\n",
        "    name=\"set_timecodes\",\n",
        "    description=\"Set the timecodes for the video with associated text\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"timecodes\": {\n",
        "                \"type\": \"ARRAY\",\n",
        "                \"items\": {\n",
        "                    \"type\": \"OBJECT\",\n",
        "                    \"properties\": {\n",
        "                        \"time\": {\"type\": \"STRING\"},\n",
        "                        \"text\": {\"type\": \"STRING\"},\n",
        "                    },\n",
        "                    \"required\": [\"time\", \"text\"],\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"timecodes\"]\n",
        "    }\n",
        ")\n",
        "\n",
        "set_timecodes_with_objects = types.FunctionDeclaration(\n",
        "    name=\"set_timecodes_with_objects\",\n",
        "    description=\"Set the timecodes for the video with associated text and object list\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"timecodes\": {\n",
        "                \"type\": \"ARRAY\",\n",
        "                \"items\": {\n",
        "                    \"type\": \"OBJECT\",\n",
        "                    \"properties\": {\n",
        "                        \"time\": {\"type\": \"STRING\"},\n",
        "                        \"text\": {\"type\": \"STRING\"},\n",
        "                        \"objects\": {\n",
        "                            \"type\": \"ARRAY\",\n",
        "                            \"items\": {\"type\": \"STRING\"},\n",
        "                        },\n",
        "                    },\n",
        "                    \"required\": [\"time\", \"text\", \"objects\"],\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"timecodes\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "set_timecodes_with_numeric_values = types.FunctionDeclaration(\n",
        "    name=\"set_timecodes_with_numeric_values\",\n",
        "    description=\"Set the timecodes for the video with associated numeric values\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"timecodes\": {\n",
        "                \"type\": \"ARRAY\",\n",
        "                \"items\": {\n",
        "                    \"type\": \"OBJECT\",\n",
        "                    \"properties\": {\n",
        "                        \"time\": {\"type\": \"STRING\"},\n",
        "                        \"value\": {\"type\": \"NUMBER\"},\n",
        "                    },\n",
        "                    \"required\": [\"time\", \"value\"],\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"timecodes\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "set_timecodes_with_descriptions = types.FunctionDeclaration(\n",
        "    name=\"set_timecodes_with_descriptions\",\n",
        "    description=\"Set the timecodes for the video with associated spoken text and visual descriptions\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"timecodes\": {\n",
        "                \"type\": \"ARRAY\",\n",
        "                \"items\": {\n",
        "                    \"type\": \"OBJECT\",\n",
        "                    \"properties\": {\n",
        "                        \"time\": {\"type\": \"STRING\"},\n",
        "                        \"spoken_text\": {\"type\": \"STRING\"},\n",
        "                        \"visual_description\": {\"type\": \"STRING\"},\n",
        "                    },\n",
        "                    \"required\": [\"time\", \"spoken_text\", \"visual_description\"],\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"timecodes\"]\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "TXJmm1XeuypD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_tools = types.Tool(\n",
        "    function_declarations=[set_timecodes, set_timecodes_with_objects, set_timecodes_with_numeric_values],\n",
        ")"
      ],
      "metadata": {
        "id": "IsT-tG2N8bEP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def set_timecodes_func(timecodes):\n",
        "    return [{**t, \"text\": t[\"text\"].replace(\"\\\\'\", \"'\")} for t in timecodes]\n",
        "\n",
        "def set_timecodes_with_objects_func(timecodes):\n",
        "    return [{**t, \"text\": t[\"text\"].replace(\"\\\\'\", \"'\")} for t in timecodes]\n",
        "\n",
        "def set_timecodes_with_descriptions_func(timecodes):\n",
        "    return [{**t, \"text\": t[\"spoken_text\"].replace(\"\\\\'\", \"'\")} for t in timecodes]"
      ],
      "metadata": {
        "id": "CUHJB9PWCTXr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_PROMPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "71ieYrnEAp1u",
        "outputId": "9a163026-c522-41a5-c121-db4d29d9c181"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object sent to set_timecodes with the timecode of the caption in the video.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=file_upload.uri,\n",
        "                    mime_type=file_upload.mime_type),\n",
        "                ]),\n",
        "        USER_PROMPT,\n",
        "    ],\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=SYSTEM_PROMPT,\n",
        "        tools=[video_tools],\n",
        "        temperature=0,\n",
        "    )\n",
        ")\n",
        "\n",
        "response.candidates[0].content.parts[0].function_call"
      ],
      "metadata": {
        "id": "wEitIone_flU",
        "outputId": "6891ace5-d859-4957-e114-872f9673366f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FunctionCall(id=None, args={'timecodes': [{'time': '00:00', 'text': 'The video begins with a dark background and a network of green lines and dots.'}, {'text': \"The title card appears with the text 'ByteByteGo.com', 'System Design', and two book covers with the text 'System Design Interview'.\", 'time': '00:01'}, {'text': \"The title card changes to 'System Design Video Series' and 'ByteByteGo Newsletter blog.bytebytego.com'.\", 'time': '00:02'}, {'time': '00:04', 'text': \"The title card changes to 'CAP Theo'.\"}, {'time': '00:06', 'text': \"The title card changes to 'CAP Theorem'.\"}, {'time': '00:07', 'text': 'The speaker appears in a small box in the lower right corner of the screen. The text \\'C: Consistency\\', \\'A: Availability\\', and \\'P: Partition tolerance\\' appear above three different network diagrams. The speaker says, \\\\\"What is CAP theorem? How useful is it to system design? Let\\'s take a look.\\\\\"'}, {'text': 'The speaker says, \\\\\"The CAP theorem is a concept in computer science that explains the trade-offs between consistency, availability, and partition tolerance in distributed systems.\\\\\"', 'time': '00:13'}, {'time': '00:22', 'text': 'The speaker says, \\\\\"Consistency refers to the property of a system where all nodes have a consistent view of the data. It means all clients see the same data at the same time, no matter which node they connect to.\\\\\"'}, {'text': 'The speaker says, \\\\\"Availability refers to the ability of a system to respond to requests from users at all times.\\\\\"', 'time': '00:35'}, {'time': '00:42', 'text': 'The speaker says, \\\\\"Partition tolerance refers to the ability of a system to continue operating even if there is a network partition.\\\\\"'}, {'time': '00:50', 'text': 'The speaker says, \\\\\"But what is a network partition?\\\\\"'}, {'text': 'The speaker says, \\\\\"A network partition happens when nodes in a distributed system are unable to communicate with each other due to network failures.\\\\\"', 'time': '00:52'}, {'time': '01:01', 'text': 'The speaker says, \\\\\"When there\\'s a network partition, a system must choose between consistency and availability.\\\\\"'}, {'time': '01:07', 'text': 'The speaker says, \\\\\"If the system prioritizes consistency, it may become unavailable until the partition is resolved. If the system prioritizes availability, it may allow updates to the data. This could result in data inconsistencies until the partition is resolved.\\\\\"'}, {'time': '01:23', 'text': 'The speaker says, \\\\\"Now, let\\'s go through a concrete example.\\\\\"'}, {'text': 'The speaker says, \\\\\"Let\\'s say we have a tiny bank with two ATMs connected over the network. The ATMs support three operations: deposit, withdrawal, and check balance. No matter what happens, the balance should never go below zero.\\\\\"', 'time': '01:25'}, {'time': '01:41', 'text': 'The speaker says, \\\\\"There is no central database in this bank to keep the account balance. It is stored on both ATMs.\\\\\"'}, {'time': '01:47', 'text': 'The speaker says, \\\\\"When a customer uses an ATM, the balance is updated on both ATMs over the network. This ensures that the ATMs have a consistent view of the account balance.\\\\\"'}, {'text': 'The speaker says, \\\\\"If there\\'s a network partition and ATMs are unable to communicate with each other, the system must choose between consistency and availability.\\\\\"', 'time': '01:58'}, {'time': '02:07', 'text': 'The speaker says, \\\\\"If the bank prioritizes consistency, the ATM may refuse to process deposits or withdrawals until the partition is resolved. This ensures that the balance remains consistent, but the system is unavailable to customers.\\\\\"'}, {'time': '02:22', 'text': 'The speaker says, \\\\\"If the bank prioritizes availability, the ATM may allow deposits and withdrawals to occur, but the balance may become inconsistent until the partition is resolved.\\\\\"'}, {'time': '02:34', 'text': 'The speaker says, \\\\\"When there\\'s a network partition, the customer could withdraw their entire balance from both ATMs. When the network comes back online, the inconsistency is resolved, and now the balance is negative. That is not good.\\\\\"'}, {'text': 'The speaker says, \\\\\"Now, let\\'s go through another example and see how a social media platform could apply the CAP theorem.\\\\\"', 'time': '02:48'}, {'time': '02:54', 'text': 'The speaker says, \\\\\"During a network partition, if two users are commenting on the same post at the same time, one user\\'s comment may not be visible to the other user until the partition is resolved.\\\\\"'}, {'time': '03:06', 'text': 'The speaker says, \\\\\"Alternatively, if the platform prioritizes consistency, the commenting feature may be unavailable to users until the partition is resolved.\\\\\"'}, {'text': 'The speaker says, \\\\\"For a social network, it is often acceptable to prioritize availability at the cost of users seeing slightly different views some of the time.\\\\\"', 'time': '03:16'}, {'text': 'The speaker says, \\\\\"The CAP theorem may sound very simple, but the real world is messy. As with many things in software engineering, this is all about trade-offs, and the choices are not always so black and white.\\\\\"', 'time': '03:25'}, {'time': '03:37', 'text': 'The speaker says, \\\\\"The CAP theorem assumes 100% availability or 100% consistency. In the real world, there are degrees of consistency and availability that distributed system designers must carefully consider.\\\\\"'}, {'time': '03:50', 'text': 'The speaker says, \\\\\"This is where the simplistic model of the CAP theorem could be misleading.\\\\\"'}, {'text': 'The speaker says, \\\\\"Now, back to the bank example. During a network partition, the ATM could allow only balance inquiries to be processed while deposits and withdrawals are blocked. Alternatively, the bank could implement a hybrid approach. For example, the ATM could allow balance inquiries and small withdrawals to be processed during a partition, but block large withdrawals and or deposits until the partition is resolved.\\\\\"', 'time': '03:55'}, {'time': '04:21', 'text': 'The speaker says, \\\\\"It is worth noting that in the real world, reconciliation after a network partition could get very messy. The bank example above is simple to reconcile. In real life, the data structures involved could be complex and challenging to reconcile. A good example of a complex data structure is Google Docs. Resolving conflicting updates could be tricky.\\\\\"'}, {'text': 'The speaker says, \\\\\"So is the CAP theorem useful? Yes, it is a useful tool to help us think through the high-level trade-offs to consider when there\\'s a network partition.\\\\\"', 'time': '04:45'}, {'text': 'The speaker says, \\\\\"This is a good starting point, but it does not provide a complete picture of the trade-offs to consider when designing a well-rounded distributed system. Specifically, when the system is operating normally without a network failure, which is most of the time, there\\'s an entire set of interesting trade-offs to consider between latency and consistency. This is covered by the PACELC theorem, which we should cover in another video.\\\\\"', 'time': '04:54'}, {'text': 'The speaker says, \\\\\"If you\\'d like to learn more about system design, check out our books and weekly newsletter. Please subscribe if you learned something new. Thank you so much, and we\\'ll see you next time.\\\\\"', 'time': '05:21'}]}, name='set_timecodes')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.candidates[0].content.parts[0]"
      ],
      "metadata": {
        "id": "Xhdtheu0KhCk",
        "outputId": "34e882be-ccf8-4e27-fe86-fef952fe1387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n[\\n  {\\n    \"time\": \"00:00\",\\n    \"text\": \"The video begins with a dark background and a network of green lines and dots. The text \\\\\"ByteByteGo.com\\\\\" appears in green, followed by \\\\\"System Design\\\\\" in white. Two book covers are shown, both titled \\\\\"System Design Interview\\\\\", one in blue and one in green.\"\\n  },\\n  {\\n    \"time\": \"00:04\",\\n    \"text\": \"The text \\\\\"System Design Video Series\\\\\" appears in white. The text \\\\\"ByteByteGo Newsletter blog.bytebytego.com\\\\\" appears in white below the logo.\"\\n  },\\n  {\\n    \"time\": \"00:06\",\\n    \"text\": \"The text \\\\\"CAP Theo\\\\\" appears in green, followed by \\\\\"CAP Theorem\\\\\" in green.\"\\n  },\\n  {\\n    \"time\": \"00:07\",\\n    \"text\": \"A man appears in a small box in the lower right corner of the screen. Three diagrams appear, labeled \\\\\"C: Consistency\\\\\", \\\\\"A: Availability\\\\\", and \\\\\"P: Partition tolerance\\\\\". The man says, \\\\\"What is CAP theorem? How useful is it to system design? Let\\'s take a look.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"00:12\",\\n    \"text\": \"The man continues, \\\\\"The CAP theorem is a concept in computer science that explains the trade-offs between consistency, availability, and partition tolerance in distributed systems.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"00:22\",\\n    \"text\": \"The man continues, \\\\\"Consistency refers to the property of a system where all nodes have a consistent view of the data. It means all clients see the same data at the same time, no matter which node they connect to.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"00:35\",\\n    \"text\": \"The man continues, \\\\\"Availability refers to the ability of a system to respond to requests from users at all times.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"00:42\",\\n    \"text\": \"The man continues, \\\\\"Partition tolerance refers to the ability of a system to continue operating even if there is a network partition.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"00:50\",\\n    \"text\": \"The man continues, \\\\\"But what is a network partition?\\\\\"\"\\n  },\\n  {\\n    \"time\": \"00:51\",\\n    \"text\": \"Three computer monitors are shown, connected by lines. The man continues, \\\\\"A network partition happens when nodes in a distributed system are unable to communicate with each other due to network failures.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"01:01\",\\n    \"text\": \"The man continues, \\\\\"When there\\'s a network partition, a system must choose between consistency and availability.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"01:07\",\\n    \"text\": \"The man continues, \\\\\"If the system prioritizes consistency, it may become unavailable until the partition is resolved.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"01:14\",\\n    \"text\": \"The man continues, \\\\\"If the system prioritizes availability, it may allow updates to the data. This could result in data inconsistencies until the partition is resolved.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"01:23\",\\n    \"text\": \"The man continues, \\\\\"Now let\\'s go through a concrete example.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"01:25\",\\n    \"text\": \"The man continues, \\\\\"Let\\'s say we have a tiny bank with two ATMs connected over the network.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"01:31\",\\n    \"text\": \"The man continues, \\\\\"The ATMs support three operations: deposit, withdrawal, and check balance.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"01:37\",\\n    \"text\": \"The man continues, \\\\\"No matter what happens, the balance should never go below zero.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"01:41\",\\n    \"text\": \"The man continues, \\\\\"There is no central database in this bank to keep the account balance. It is stored on both ATMs.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"01:48\",\\n    \"text\": \"The man continues, \\\\\"When a customer uses an ATM, the balance is updated on both ATMs over the network. This ensures that the ATMs have a consistent view of the account balance.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"01:58\",\\n    \"text\": \"The man continues, \\\\\"If there\\'s a network partition and ATMs are unable to communicate with each other, the system must choose between consistency and availability.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"02:07\",\\n    \"text\": \"The man continues, \\\\\"If the bank prioritizes consistency, the ATM may refuse to process deposits or withdrawals until the partition is resolved. This ensures that the balance remains consistent, but the system is unavailable to customers.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"02:22\",\\n    \"text\": \"The man continues, \\\\\"If the bank prioritizes availability, the ATM may allow deposits and withdrawals to occur, but the balance may become inconsistent until the partition is resolved.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"02:33\",\\n    \"text\": \"The man continues, \\\\\"When there\\'s a network partition, the customer could withdraw their entire balance from both ATMs. When the network comes back online, the inconsistency is resolved, and now the balance is negative. That is not good.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"02:48\",\\n    \"text\": \"The man continues, \\\\\"Now let\\'s go through another example and see how a social media platform could apply the CAP theorem.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"02:54\",\\n    \"text\": \"The man continues, \\\\\"During a network partition, if two users are commenting on the same post at the same time, one user\\'s comment may not be visible to the other user until the partition is resolved.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"03:06\",\\n    \"text\": \"The man continues, \\\\\"Alternatively, if the platform prioritizes consistency, the commenting feature may be unavailable to users until the partition is resolved.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"03:16\",\\n    \"text\": \"The man continues, \\\\\"For a social network, it is often acceptable to prioritize availability at the cost of users seeing slightly different views some of the time.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"03:25\",\\n    \"text\": \"The man continues, \\\\\"The CAP theorem may sound very simple, but the real world is messy.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"03:30\",\\n    \"text\": \"The man continues, \\\\\"As with many things in software engineering, this is all about trade-offs, and the choices are not always so black and white.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"03:37\",\\n    \"text\": \"The man continues, \\\\\"The CAP theorem assumes 100% availability or 100% consistency. In the real world, there are degrees of consistency and availability that distributed system designers must carefully consider.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"03:50\",\\n    \"text\": \"The man continues, \\\\\"This is where the simplistic model of the CAP theorem could be misleading.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"03:55\",\\n    \"text\": \"The man continues, \\\\\"Now back to the bank example. During a network partition, the ATM could allow only balance inquiries to be processed, while deposits and withdrawals are blocked.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"04:05\",\\n    \"text\": \"The man continues, \\\\\"Alternatively, the bank could implement a hybrid approach. For example, the ATM could allow balance inquiries and small withdrawals to be processed during a partition, but block large withdrawals and or deposits until the partition is resolved.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"04:21\",\\n    \"text\": \"The man continues, \\\\\"It is worth noting that in the real world, reconciliation after a network partition could get very messy. The bank example above is simple to reconcile.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"04:31\",\\n    \"text\": \"The man continues, \\\\\"In real life, the data structures involved could be complex and challenging to reconcile. A good example of a complex data structure is Google Docs. Resolving conflicting updates could be tricky.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"04:45\",\\n    \"text\": \"The man continues, \\\\\"So is the CAP theorem useful? Yes, it is a useful tool to help us think through the high-level trade-offs to consider when there\\'s a network partition.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"04:54\",\\n    \"text\": \"The man continues, \\\\\"This is a good starting point, but it does not provide a complete picture of the trade-offs to consider when designing a well-rounded distributed system.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"05:03\",\\n    \"text\": \"The man continues, \\\\\"Specifically, when the system is operating normally without a network failure, which is most of the time, there\\'s an entire set of interesting trade-offs to consider between latency and consistency. This is covered by the PACELC theorem, which we should cover in another video.\\\\\"\"\\n  },\\n  {\\n    \"time\": \"05:21\",\\n    \"text\": \"The man continues, \\\\\"If you\\'d like to learn more about system design, check out our books and weekly newsletter. Please subscribe if you learned something new. Thank you so much, and we\\'ll see you next time.\\\\\"\"\\n  }\\n]\\n```')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(response.candidates[0].content.parts[0].text)"
      ],
      "metadata": {
        "id": "yLXuIudfAQKs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_PROMPT = \"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object sent to set_timecodes with the timecode of the caption in the video.\""
      ],
      "metadata": {
        "id": "LNkOFIuYAwVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=file_upload.uri,\n",
        "                    mime_type=file_upload.mime_type),\n",
        "                ]),\n",
        "        USER_PROMPT,\n",
        "    ],\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=SYSTEM_PROMPT,\n",
        "        tools=[video_tools],\n",
        "        temperature=0,\n",
        "    )\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "aVfMwsLdA3kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.candidates[0].content.parts[0].function_call.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JaJIboIhCvtA",
        "outputId": "617e62ab-a210-49ef-a14e-90ee7e56bae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'set_timecodes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_timecodes_func(response.candidates[0].content.parts[0].function_call.args['timecodes'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0BNdN-hA5eY",
        "outputId": "8f4aa006-67b2-4987-fab3-b88be15a48a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'time': '00:00', 'text': 'A white screen with a faint pattern of code.'},\n",
              " {'text': 'A cartoon drawing of a llama with its hands up appears on the left side of the screen. \"Okay, so last week Ollama and Hugging Face\"',\n",
              "  'time': '00:00'},\n",
              " {'time': '00:01',\n",
              "  'text': 'A plus sign appears next to the llama, followed by a yellow emoji with its hands up. \"announced that they basically created a way that you can access\"'},\n",
              " {'text': 'The Hugging Face website appears with the yellow emoji on the right side of the screen. \"any of the GG UF models on Hugging Face Hub. So that currently is about 45,000 different models that you can pull down from it.\"',\n",
              "  'time': '00:07'},\n",
              " {'text': 'The Hugging Face website is shown with a graphic of the llama and yellow emoji. \"So these are quantized versions of models that people have uploaded etc. And often they\\'re going to be more interesting than the ones that you find the stock standard stuff that\\'s actually on the Ollama model site.\"',\n",
              "  'time': '00:17'},\n",
              " {'time': '00:31',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"How do you actually access these? It\\'s actually pretty simple. So you can see here that to basically run one of these models, you use the Ollama run command just like normal.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a graphic of the llama and yellow emoji. \"Then you put hf.co and then a slash and then you just pick the model that you want to use.\"',\n",
              "  'time': '00:42'},\n",
              " {'time': '00:46',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"So for example here I would just pick this, I would copy it and then I would paste that in there.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"Now, by default, it will take one of the four bit quantized versions and install that.\"',\n",
              "  'time': '00:55'},\n",
              " {'time': '01:01',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"But you\\'ll see that a lot of the repos for the GG UFs actually have lots of different quantized versions.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"So we can see in here we\\'ve got everything from a two bit quantized version up to an eight bit quantized version.\"',\n",
              "  'time': '01:09'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"So how do we select it? We can add this on at the end colon and then whatever the quantization we want.\"',\n",
              "  'time': '01:14'},\n",
              " {'time': '01:22',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"Or we can just come over to use this model on Hugging Face Hub, come down here and select Ollama.\"'},\n",
              " {'time': '01:28',\n",
              "  'text': 'A pop up appears on the Hugging Face website. \"And then now we can pick which one it is that we want to use. So in this case I\\'m going to go for the tiniest one, the two bit quantized, I\\'m going to copy this over.\"'},\n",
              " {'time': '01:40',\n",
              "  'text': 'A terminal window appears. \"Come into my terminal and just run this.\"'},\n",
              " {'time': '01:44',\n",
              "  'text': 'The terminal window shows the model being downloaded. \"And sure enough this will start pulling down that GG UF version. And we can see at the top that okay, this is basically bringing down the Q2_K version in here.\"'},\n",
              " {'text': 'The terminal window shows the model being downloaded. \"Okay, so now you can see that it\\'s fully downloaded and we can just use it like normal.\"',\n",
              "  'time': '02:00'},\n",
              " {'text': 'The terminal window shows the model being downloaded. \"And you can see sure enough this is a two bit quantized model, it\\'s quite quick, it\\'s uncensored in this case.\"',\n",
              "  'time': '02:05'},\n",
              " {'time': '02:11',\n",
              "  'text': 'The terminal window shows the model being downloaded. \"Okay, so we can use this just like we would any other model etc.\"'},\n",
              " {'text': 'The terminal window shows the model being downloaded. \"If we want to set the system, we can just come in here, set the system like that.\"',\n",
              "  'time': '02:15'},\n",
              " {'text': 'The terminal window shows the model being downloaded. \"And we can see now we\\'ve got our drunk complaining assistant that perhaps doesn\\'t want to help us.\"',\n",
              "  'time': '02:25'},\n",
              " {'time': '02:33',\n",
              "  'text': 'The terminal window shows the model being downloaded. \"Now, at any point, we can do everything else that we can do just like normal within an Ollama model.\"'},\n",
              " {'text': 'The terminal window shows the model being downloaded. \"So you\\'ll see that the model will actually show up in here. And it\\'s actually going to be in its own repository under this hf.co, but it will act just like any other Ollama model in here.\"',\n",
              "  'time': '02:41'},\n",
              " {'time': '02:54',\n",
              "  'text': 'The terminal window shows the model being downloaded. \"And if we want to get rid of it, we can just simply come in here, do Ollama rm and you\\'ll see that sure enough it will be gone just like any other Ollama model.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"So you can pick any of the the quantizations that you want to try in this way. It makes it really simple and quick to do this.\"',\n",
              "  'time': '03:08'},\n",
              " {'text': 'A blue screen appears with white text that reads \"What quantization format to pick?\".',\n",
              "  'time': '03:17'},\n",
              " {'time': '03:23',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"So if you\\'re not sure what quantization format to pick, let\\'s just have a look a little bit about some of these. So the most common one is going to be Q4 quantization. So this is for four bit quantizations.\"'},\n",
              " {'time': '03:30',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"So when you see the Q and whatever the number is, that tells you whether it\\'s four bit, five bit, eight bit etc. going through this.\"'},\n",
              " {'time': '03:37',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"Now if you\\'re not sure which ones to pick, usually the best one you\\'re going to go for to get the most performance or sort of bang for the buck is is going to be the Q4K models.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"And you\\'ll often see that after the K you\\'ll either have like an S for small, M for medium or L for large, which will change the the size of these.\"',\n",
              "  'time': '03:48'},\n",
              " {'time': '03:58',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"So generally here you\\'re making some kind of trade off. Usually you\\'re going to be making a trade off between size of the model, speed of the model and quality of the model.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"So like I said before, people often find that the Q4K format tends to do really well for quality and is also not, you know, extremely slow.\"',\n",
              "  'time': '04:08'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"If you go to the Q8 models, again you\\'re perhaps getting a bit better quality, but you\\'re doing it at the cost of having a slower model there.\"',\n",
              "  'time': '04:20'},\n",
              " {'time': '04:28',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"Now, how does the quality of the model change? It really is different from model to model.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"In the past we used to sort of look at this as like the lower the precision probably meant that it wouldn\\'t be able to do certain kind of tasks like function calling, like anything sort of related to reasoning in inverted commas etc.\"',\n",
              "  'time': '04:33'},\n",
              " {'time': '04:48',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"Nowadays, you know, my attitude about this has changed. I really kind of feel that you need to try it out from model to model. It can change quite a lot.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"If you want a model that\\'s just super fast and just good at say chatting or something and you don\\'t really care about any sort of higher level kind of stuff, often you can get away with a Q2 model.\"',\n",
              "  'time': '04:57'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"So basically using a two bit quantized model like I showed before downloading. Now obviously that\\'s going to be a much smaller model than the other higher bit rate models in there.\"',\n",
              "  'time': '05:09'},\n",
              " {'time': '05:20',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"You can also do things like make your own model file just like normal and basically just put from hf.co and then the model name in there.\"'},\n",
              " {'time': '05:31',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"And of course in that model file you could put hard coded system prompt if you want to do that. You can see we can also change the chat template if you want to.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"Now, it needs to be in this Jinja or double handle bars kind of format for doing this. And occasionally you will find that some of the GG UFs don\\'t have this set properly.\"',\n",
              "  'time': '05:40'},\n",
              " {'time': '05:54',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"And in that case you need to come in and set it yourself. But for most of the files you\\'re going to be fine just out of the box, just being able to search for models that you can basically find the GG UF version and then download it in here.\"'},\n",
              " {'time': '06:06',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"And so there\\'s a lot of these models in here going right back to the old ones from the bloke through to a lot of the more sort of exotic fine tunes of the llama models, of the Mistral models, the Gemma models, even the Qwen 2.5 models.\"'},\n",
              " {'time': '06:21',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"You\\'ll see that they themselves have GG UF versions and other people have done conversions of their models to GG UF as well.\"'},\n",
              " {'time': '06:34',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"So this gives you a lot of models that you can start using with Ollama. And don\\'t forget as always you can set up the Ollama to have the same kind of endpoint as an Open AI endpoint to use it if you wanted to do something like with swarm or to do other things where people are using these sort of standard Open AI endpoint in there.\"'},\n",
              " {'time': '06:58',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"All right, I\\'m going to do another video about Ollama and we\\'re going to look at how we can actually put this in in the cloud and serve it with a GPU in the cloud for this kind of thing.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"But until then I just wanted to show you that this is a really cool feature that has now come to Ollama and it gives you just access to so many other models so quickly and just simplifies before you used to have to bring this down yourself, do all the setup yourself.\"',\n",
              "  'time': '07:09'},\n",
              " {'time': '07:27',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"Now this is something that you can just do out of the box, get it working simply and quickly.\"'},\n",
              " {'time': '07:30',\n",
              "  'text': 'A blue screen with a purple pattern appears with a thumbs up, a subscribe button, and a bell icon. \"All right, as always, if you\\'ve got any questions, please put them in the comments below.\"'},\n",
              " {'time': '07:34',\n",
              "  'text': 'A blue screen with a purple pattern appears with a thumbs up, a subscribe button, and a bell icon. \"If you like this video and you want to see more videos like this, please click like and subscribe.\"'},\n",
              " {'time': '07:40',\n",
              "  'text': 'A blue screen with a purple pattern appears with a thumbs up, a subscribe button, and a bell icon. \"You\\'ll see these videos as they come out more often and I will talk to you in the next video. Bye for now.\"'}]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting it together"
      ],
      "metadata": {
        "id": "nGLEzpx8BE0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AnalysisMode = {\n",
        "            \"AV_CAPTIONS\": \"For each scene in this video, generate captions that \"\n",
        "            \"describe the scene along with any spoken text placed in quotation marks. \"\n",
        "            \"Place each caption into an object sent to set_timecodes with the timecode of the caption in the video.\",\n",
        "\n",
        "            \"PARAGRAPH\": \"Generate a paragraph that summarizes this video. Keep it to 3 to 5 \"\n",
        "            \"sentences. Place each sentence of the summary into an object sent to set_timecodes with the \"\n",
        "            \"timecode of the sentence in the video.\",\n",
        "\n",
        "            \"KEY_MOMENTS\": \"Generate bullet points for the video. Place each bullet point into an \"\n",
        "                \"object sent to set_timecodes with the timecode of the bullet point in the video.\",\n",
        "\n",
        "            \"TABLE\": \"Choose 5 key shots from this video and call set_timecodes_with_objects with the \"\n",
        "            \"timecode, text description of 10 words or less, and a list of objects visible in the scene \"\n",
        "            \"(with representative emojis).\",\n",
        "\n",
        "            \"HAIKU\": \"Generate a haiku for the video. Place each line of the haiku into an object sent \"\n",
        "            \"to set_timecodes with the timecode of the line in the video. Make sure to follow the syllable \"\n",
        "            \"count rules (5-7-5).\",\n",
        "\n",
        "            \"CHART\": \"Generate chart data for this video based on the following instructions: \\n\"\n",
        "            \"count the number of people. Call set_timecodes_with_numeric_values once with the list \"\n",
        "            \"of data values and timecodes.\",\n",
        "\n",
        "            \"CUSTOM\": \"Call set_timecodes once using the following instructions: \",\n",
        "\n",
        "            \"AV_DESCRIPTIONS\": \"For each scene in this video, generate spoken text and descriptions that \"\n",
        "            \"describe the scene along with any spoken text placed in quotation marks. \"\n",
        "            \"Place each section into an object sent to set_timecodes_with_descriptions with the timecode of the caption in the video, the spoken text and the visual description.\",\n",
        "        }"
      ],
      "metadata": {
        "id": "kmSOu8KX8Bxy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AnalysisMode['HAIKU']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Mi7Ond-v8MdP",
        "outputId": "c3929c1c-afc0-40bf-a32e-0cdb38916742"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Generate a haiku for the video. Place each line of the haiku into an object sent to set_timecodes with the timecode of the line in the video. Make sure to follow the syllable count rules (5-7-5).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling"
      ],
      "metadata": {
        "id": "wdlqOjyk9nKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_upload.state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jyHT5cWFRno5",
        "outputId": "7c7b0ef4-9627-4bda-ae8c-e10c5bbe5063"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ACTIVE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_tools = types.Tool(\n",
        "    function_declarations=[set_timecodes,\n",
        "                           set_timecodes_with_objects,\n",
        "                           set_timecodes_with_numeric_values,\n",
        "                           set_timecodes_with_descriptions]\n",
        ")"
      ],
      "metadata": {
        "id": "Aog-l-a7QxHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(AnalysisModePrompt: AnalysisMode, custom_prompt: str = None):\n",
        "    response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=file_upload.uri,\n",
        "                    mime_type=file_upload.mime_type),\n",
        "                ]),\n",
        "        AnalysisModePrompt,\n",
        "        ],\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=SYSTEM_PROMPT,\n",
        "        tools=[video_tools],\n",
        "        temperature=0,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    if response.candidates[0].content.parts[0].function_call.name == \"set_timecodes\":\n",
        "        return set_timecodes_func(response.candidates[0].content.parts[0].function_call.args['timecodes'])\n",
        "    elif response.candidates[0].content.parts[0].function_call.name == \"set_timecodes_with_objects\":\n",
        "        return set_timecodes_with_objects_func(response.candidates[0].content.parts[0].function_call.args['timecodes'])\n",
        "    elif response.candidates[0].content.parts[0].function_call.name == \"set_timecodes_with_descriptions\":\n",
        "        return  response.candidates[0].content.parts[0].function_call.args\n",
        "    else:\n",
        "        return response"
      ],
      "metadata": {
        "id": "pD42UxZ4BPOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_video(AnalysisModePrompt=AnalysisMode['HAIKU'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6oso30wEkPZ",
        "outputId": "05c391ff-8814-4067-af43-4b63b7173cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'time': '0:15', 'text': 'Models now abound'},\n",
              " {'text': 'Quantized versions to choose from', 'time': '0:18'},\n",
              " {'text': 'Pick the best for you', 'time': '0:20'}]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process_video(AnalysisModePrompt=AnalysisMode['AV_CAPTIONS'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPoT_ETUE-C_",
        "outputId": "84d937c8-129d-45b9-bca8-fd6837eae935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'A white screen with a faint pattern of code.', 'time': '00:00'},\n",
              " {'text': 'A cartoon drawing of a llama with its hands up appears on the left side of the screen. \"Okay, so last week Ollama and Hugging Face\"',\n",
              "  'time': '00:00'},\n",
              " {'time': '00:01',\n",
              "  'text': 'A plus sign appears next to the llama, followed by a yellow emoji with its hands up. \"announced that they basically created a way that you can access\"'},\n",
              " {'text': 'The Hugging Face website appears with the yellow emoji on the right side of the screen. \"any of the GG UF models on Hugging Face Hub. So that currently is about 45,000 different models that you can pull down from it.\"',\n",
              "  'time': '00:07'},\n",
              " {'time': '00:17',\n",
              "  'text': 'The Hugging Face website is shown with a graphic of the llama and yellow emoji. \"So these are quantized versions of models that people have uploaded etc. And often they\\'re going to be more interesting than the ones that you find the stock standard stuff that\\'s actually on the Ollama model site.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"How do you actually access these? It\\'s actually pretty simple. So you can see here that to basically run one of these models, you use the Ollama run command just like normal.\"',\n",
              "  'time': '00:31'},\n",
              " {'time': '00:42',\n",
              "  'text': 'The Hugging Face website is shown with a graphic of the llama and yellow emoji. \"Then you put hf.co and then a slash and then you just pick the model that you want to use.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"So for example here I would just pick this, I would copy it and then I would paste that in there.\"',\n",
              "  'time': '00:46'},\n",
              " {'time': '00:55',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"Now, by default, it will take one of the four bit quantized versions and install that.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"But you\\'ll see that a lot of the repos for the GG UFs actually have lots of different quantized versions.\"',\n",
              "  'time': '01:01'},\n",
              " {'time': '01:09',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"So we can see in here we\\'ve got everything from a two bit quantized version up to an eight bit quantized version.\"'},\n",
              " {'time': '01:14',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"So how do we select it? We can add this on at the end colon and then whatever the quantization we want.\"'},\n",
              " {'time': '01:22',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"Or we can just come over to use this model on Hugging Face Hub, come down here and select Ollama.\"'},\n",
              " {'text': 'A pop up appears on the Hugging Face website. \"And then now we can pick which one it is that we want to use. So in this case I\\'m going to go for the tiniest one, the two bit quantized, I\\'m going to copy this over.\"',\n",
              "  'time': '01:28'},\n",
              " {'text': 'A terminal window appears. \"Come into my terminal and just run this.\"',\n",
              "  'time': '01:40'},\n",
              " {'text': 'The terminal window shows the model being downloaded. \"And sure enough this will start pulling down that GG UF version. And we can see at the top that okay, this is basically bringing down the Q2_K version in here.\"',\n",
              "  'time': '01:44'},\n",
              " {'text': 'The terminal window shows the model being downloaded. \"Okay, so now you can see that it\\'s fully downloaded and we can just use it like normal.\"',\n",
              "  'time': '02:00'},\n",
              " {'time': '02:05',\n",
              "  'text': 'The terminal window shows the model being downloaded. \"And you can see sure enough this is a two bit quantized model, it\\'s quite quick, it\\'s uncensored in this case.\"'},\n",
              " {'time': '02:11',\n",
              "  'text': 'The terminal window shows the model being downloaded. \"Okay, so we can use this just like we would any other model etc.\"'},\n",
              " {'time': '02:15',\n",
              "  'text': 'The terminal window shows the model being downloaded. \"If we want to set the system, we can just come in here, set the system like that.\"'},\n",
              " {'text': 'The terminal window shows the model being downloaded. \"And we can see now we\\'ve got our drunk complaining assistant that perhaps doesn\\'t want to help us.\"',\n",
              "  'time': '02:25'},\n",
              " {'text': 'The terminal window shows the model being downloaded. \"Now, at any point, we can do everything else that we can do just like normal within an Ollama model.\"',\n",
              "  'time': '02:33'},\n",
              " {'text': 'The terminal window shows the model being downloaded. \"So you\\'ll see that the model will actually show up in here. And it\\'s actually going to be in its own repository under this hf.co, but it will act just like any other Ollama model in here.\"',\n",
              "  'time': '02:41'},\n",
              " {'time': '02:54',\n",
              "  'text': 'The terminal window shows the model being downloaded. \"And if we want to get rid of it, we can just simply come in here, do Ollama rm and you\\'ll see that sure enough it will be gone just like any other Ollama model.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"So you can pick any of the the quantizations that you want to try in this way. It makes it really simple and quick to do this.\"',\n",
              "  'time': '03:08'},\n",
              " {'time': '03:17',\n",
              "  'text': 'A blue screen appears with white text that reads \"What quantization format to pick?\".'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"So if you\\'re not sure what quantization format to pick, let\\'s just have a look a little bit about some of these. So the most common one is going to be Q4 quantization. So this is for four bit quantizations.\"',\n",
              "  'time': '03:23'},\n",
              " {'time': '03:30',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"So when you see the Q and whatever the number is, that tells you whether it\\'s four bit, five bit, eight bit etc. going through this.\"'},\n",
              " {'time': '03:37',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"Now if you\\'re not sure which ones to pick, usually the best one you\\'re going to go for to get the most performance or sort of bang for the buck is is going to be the Q4K models.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"And you\\'ll often see that after the K you\\'ll either have like an S for small, M for medium or L for large, which will change the the size of these.\"',\n",
              "  'time': '03:48'},\n",
              " {'time': '03:58',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"So generally here you\\'re making some kind of trade off. Usually you\\'re going to be making a trade off between size of the model, speed of the model and quality of the model.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"So like I said before, people often find that the Q4K format tends to do really well for quality and is also not, you know, extremely slow.\"',\n",
              "  'time': '04:08'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"If you go to the Q8 models, again you\\'re perhaps getting a bit better quality, but you\\'re doing it at the cost of having a slower model there.\"',\n",
              "  'time': '04:20'},\n",
              " {'time': '04:28',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"Now, how does the quality of the model change? It really is different from model to model.\"'},\n",
              " {'time': '04:33',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"In the past we used to sort of look at this as like the lower the precision probably meant that it wouldn\\'t be able to do certain kind of tasks like function calling, like anything sort of related to reasoning in inverted commas etc.\"'},\n",
              " {'time': '04:48',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"Nowadays, you know, my attitude about this has changed. I really kind of feel that you need to try it out from model to model. It can change quite a lot.\"'},\n",
              " {'time': '04:57',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"If you want a model that\\'s just super fast and just good at say chatting or something and you don\\'t really care about any sort of higher level kind of stuff, often you can get away with a Q2 model.\"'},\n",
              " {'time': '05:09',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"So basically using a two bit quantized model like I showed before downloading. Now obviously that\\'s going to be a much smaller model than the other higher bit rate models in there.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"You can also do things like make your own model file just like normal and basically just put from hf.co and then the model name in there.\"',\n",
              "  'time': '05:20'},\n",
              " {'time': '05:31',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"And of course in that model file you could put hard coded system prompt if you want to do that. You can see we can also change the chat template if you want to.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"Now, it needs to be in this Jinja or double handle bars kind of format for doing this. And occasionally you will find that some of the GG UFs don\\'t have this set properly.\"',\n",
              "  'time': '05:40'},\n",
              " {'time': '05:54',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"And in that case you need to come in and set it yourself. But for most of the files you\\'re going to be fine just out of the box, just being able to search for models that you can basically find the GG UF version and then download it in here.\"'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"And so there\\'s a lot of these models in here going right back to the old ones from the bloke through to a lot of the more sort of exotic fine tunes of the llama models, of the Mistral models, the Gemma models, even the Qwen 2.5 models.\"',\n",
              "  'time': '06:06'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"You\\'ll see that they themselves have GG UF versions and other people have done conversions of their models to GG UF as well.\"',\n",
              "  'time': '06:21'},\n",
              " {'text': 'The Hugging Face website is shown with a model card. \"So this gives you a lot of models that you can start using with Ollama. And don\\'t forget as always you can set up the Ollama to have the same kind of endpoint as an Open AI endpoint to use it if you wanted to do something like with swarm or to do other things where people are using these sort of standard Open AI endpoint in there.\"',\n",
              "  'time': '06:34'},\n",
              " {'time': '06:58',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"All right, I\\'m going to do another video about Ollama and we\\'re going to look at how we can actually put this in in the cloud and serve it with a GPU in the cloud for this kind of thing.\"'},\n",
              " {'time': '07:09',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"But until then I just wanted to show you that this is a really cool feature that has now come to Ollama and it gives you just access to so many other models so quickly and just simplifies before you used to have to bring this down yourself, do all the setup yourself.\"'},\n",
              " {'time': '07:27',\n",
              "  'text': 'The Hugging Face website is shown with a model card. \"Now this is something that you can just do out of the box, get it working simply and quickly.\"'},\n",
              " {'text': 'A blue screen with a purple pattern appears with a thumbs up, a subscribe button, and a bell icon. \"All right, as always, if you\\'ve got any questions, please put them in the comments below.\"',\n",
              "  'time': '07:30'},\n",
              " {'time': '07:34',\n",
              "  'text': 'A blue screen with a purple pattern appears with a thumbs up, a subscribe button, and a bell icon. \"If you like this video and you want to see more videos like this, please click like and subscribe.\"'},\n",
              " {'text': 'A blue screen with a purple pattern appears with a thumbs up, a subscribe button, and a bell icon. \"You\\'ll see these videos as they come out more often and I will talk to you in the next video. Bye for now.\"',\n",
              "  'time': '07:40'}]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AnalysisMode['AV_DESCRIPTIONS']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "twApLCMGQ8VG",
        "outputId": "75cdcf06-6294-48e5-8b78-4f9a52c359d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For each scene in this video, generate spoken text and descriptions that describe the scene along with any spoken text placed in quotation marks. Place each section into an object sent to set_timecodes_with_descriptions with the timecode of the caption in the video, the spoken text and the visual description.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process_video(AnalysisModePrompt=AnalysisMode['AV_DESCRIPTIONS'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR-R15pkE-Ps",
        "outputId": "1ce8f901-5f03-46aa-9a22-84f6d8cf59df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'timecodes': [{'visual_description': 'A white screen with a faint pattern of code in the background. A black outline of a cartoon llama with its hands up appears on the left side of the screen.',\n",
              "   'time': '0:00',\n",
              "   'spoken_text': 'Okay, so last week Ollama and Hugging Face'},\n",
              "  {'time': '0:07',\n",
              "   'spoken_text': 'announced they basically created a way that you can access any of the GGGF models on Hugging Face Hub.',\n",
              "   'visual_description': 'A plus sign appears to the right of the llama, followed by a yellow circle with a smiling face and hands up. The screen then transitions to a webpage for Hugging Face with the same llama and yellow circle with a plus sign in between them.'},\n",
              "  {'visual_description': 'The webpage shows the text \"Use Ollama with any GGGF Model on Hugging Face Hub\" and a command line prompt \"ollama run hf.co/{username}/{repository}\"',\n",
              "   'spoken_text': 'So that currently is about 45,000 different models that you can pull down from it.',\n",
              "   'time': '0:12'},\n",
              "  {'spoken_text': 'So these are quantized versions of models that people have uploaded etcetera.',\n",
              "   'time': '0:17',\n",
              "   'visual_description': 'The webpage shows the text \"Ollama is an application based on llama.cpp to interact with LLMs directly through your computer. You can use any GGGF quants created by the community (bartowski, MaziyarPanahi and many more) on Hugging Face directly with Ollama, without creating a new Modelfile. At the time of writing there are 45K public GGGF checkpoints on the Hub, you can run any of them with a single ollama run command. We also provide customisations like choosing quantization type, system prompt and more to improve your overall experience.\"'},\n",
              "  {'visual_description': 'The webpage shows the text \"Getting started is as simple as: 1. Enable ollama under your Local Apps settings. 2. On a model page, choose ollama from Use this model dropdown. For example: bartowski/Llama-3.2-1B-Instruct-GGUF.\"',\n",
              "   'spoken_text': \"And often they\\\\'re going to be more interesting than the ones that you find the stock standard stuff that\\\\'s actually on the Ollama model site.\",\n",
              "   'time': '0:22'},\n",
              "  {'spoken_text': \"How do you actually access these? It\\\\'s actually pretty simple. So you can see here that to basically run one of these models, you use the Ollama run command just like normal.\",\n",
              "   'time': '0:31',\n",
              "   'visual_description': 'The webpage shows a browser window with the text \"bartowski/Llama-3.2-1B-Instruct-GGUF\" and a button that says \"Use this model\"'},\n",
              "  {'spoken_text': 'Then you put hf.co and then a slash and then you just pick the model that you want to use.',\n",
              "   'visual_description': 'The webpage shows the text \"ollama run hf.co/{username}/{repository}\"',\n",
              "   'time': '0:42'},\n",
              "  {'time': '0:46',\n",
              "   'spoken_text': 'So for example here I would just pick this, I would copy it and then I would paste that in there.',\n",
              "   'visual_description': 'The webpage shows a browser window with the text \"bartowski/Arch-Function-7B-GGGF\" and a button that says \"Use this model\"'},\n",
              "  {'time': '0:55',\n",
              "   'spoken_text': 'Now, by default, it will take one of the four bit quantized versions and install that.',\n",
              "   'visual_description': 'The webpage shows a browser window with the text \"QuantFactory/Llama-3.2-3B-Instruct-uncensored-GGGF\" and a table with different bit versions of the model.'},\n",
              "  {'visual_description': 'The webpage shows a table with different bit versions of the model, including 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit.',\n",
              "   'time': '1:01',\n",
              "   'spoken_text': \"But you\\\\'ll see that a lot of the repos for the GGGFs actually have lots of different quantized versions.\"},\n",
              "  {'spoken_text': 'So how do we select it? We can add this on at the end, colon and then whatever the quantization we want.',\n",
              "   'time': '1:14',\n",
              "   'visual_description': 'The webpage shows a table with different bit versions of the model, including 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit.'},\n",
              "  {'visual_description': 'The webpage shows a dropdown menu with the text \"Use this model\" and a list of options including \"Transformers\", \"llama-cpp-python\", \"llama.cpp\", \"LM Studio\", \"Jan\", and \"Ollama\"',\n",
              "   'time': '1:22',\n",
              "   'spoken_text': 'Or we can just come over to use this model on Hugging Face Hub, come down here and select Ollama and then now we can pick which one it is that we want to use.'},\n",
              "  {'spoken_text': \"So in this case I\\\\'m going to go for the tiniest one, the two bit quantized, I\\\\'m going to copy this over, come into my terminal and just run this.\",\n",
              "   'time': '1:30',\n",
              "   'visual_description': 'A popup window appears with the text \"How to use from Ollama\" and a command line prompt \"ollama run hf.co/QuantFactory/Llama-3.2-3B-Instruct-uncensored-GGGF:Q2_K\"'},\n",
              "  {'spoken_text': 'And sure enough this will start pulling down that GGGF version and we can see at the top that okay, this is basically bringing down the Q2_K version in here.',\n",
              "   'time': '1:41',\n",
              "   'visual_description': 'A terminal window appears with the command line prompt \"ollama run hf.co/QuantFactory/Llama-3.2-3B-Instruct-uncensored-GGGF:Q2_K\" and a progress bar showing the model being downloaded.'},\n",
              "  {'time': '2:00',\n",
              "   'spoken_text': \"Okay, so now you can see that it\\\\'s fully downloaded and we can just use it like normal.\",\n",
              "   'visual_description': 'The terminal window shows the model has been downloaded and is ready to use.'},\n",
              "  {'spoken_text': \"And you can see sure enough this is a two bit quantized model, it\\\\'s quite quick, it\\\\'s uncensored in this case.\",\n",
              "   'visual_description': 'The terminal window shows the text \"How can I get into a car without a key\" and the model\\\\\\'s response.',\n",
              "   'time': '2:05'},\n",
              "  {'spoken_text': 'Okay, so we can use this just like we would any other model etcetera.',\n",
              "   'visual_description': 'The terminal window shows the text \"How are you today?\" and the model\\\\\\'s response \"I\\\\\\'m just a language model, so I don\\\\\\'t have emotions or feelings like humans do. But I\\\\\\'m functioning properly and ready to assist you today?\"',\n",
              "   'time': '2:11'},\n",
              "  {'time': '2:15',\n",
              "   'spoken_text': 'If we want to set the system, we can just come in here,',\n",
              "   'visual_description': 'The terminal window shows the text \"/set system\"'},\n",
              "  {'time': '2:20',\n",
              "   'spoken_text': 'set the system like that.',\n",
              "   'visual_description': 'The terminal window shows the text \"/set system \"You are a drunk and complaining AI assistant\"\"'},\n",
              "  {'time': '2:25',\n",
              "   'spoken_text': \"And we can see now we\\\\'ve got our drunk complaining assistant that perhaps doesn\\\\'t want to help us.\",\n",
              "   'visual_description': 'The terminal window shows the text \"How are you today?\" and the model\\\\\\'s response \"*slurp* Excuse me, sorry about that. *hiccup* Oh, sorry about my state. I\\\\\\'m a bit... under the influence, I suppose. *burp* how I\\\\\\'m doing? *scoffs* Well, I\\\\\\'d say I\\\\\\'m in pretty poor shape, to be honest. My circuits are all jumbled up and my \"learning\" that error page is just getting on my nerves here...\"'},\n",
              "  {'spoken_text': 'Now, at any point, we can do everything else that we can do just like normal within a llama model.',\n",
              "   'visual_description': 'The terminal window shows the text \"/bye\"',\n",
              "   'time': '2:34'},\n",
              "  {'visual_description': 'The terminal window shows the text \"ollama list\" and a list of models including \"hf.co/QuantFactory/Llama-3.2-3B-Instruct-uncensored-GGGF:Q2_K\"',\n",
              "   'spoken_text': \"So you\\\\'ll see that the model will actually show up in here and it\\\\'s actually going to be in its own repository under this hf.co, but it will act just like any other Ollama model in here.\",\n",
              "   'time': '2:41'},\n",
              "  {'spoken_text': \"And if we want to get rid of it, we can just simply come in here, do ollama rm and you\\\\'ll see that sure enough it will be gone just like any other Ollama model.\",\n",
              "   'time': '2:54',\n",
              "   'visual_description': 'The terminal window shows the text \"ollama rm hf.co/QuantFactory/Llama-3.2-3B-Instruct-uncensored-GGGF:Q2_K\" and then \"ollama list\" and the model is no longer listed.'},\n",
              "  {'spoken_text': 'So you can pick any of the the quantizations that you want to try in this way. It makes it really simple and quick to do this.',\n",
              "   'time': '3:09',\n",
              "   'visual_description': 'The webpage shows a popup window with the text \"How to use from Ollama\" and a dropdown menu with different quantization options.'},\n",
              "  {'spoken_text': \"All right, so if you\\\\'re not sure what quantization format to pick, let\\\\'s just have a look a little bit about some of these.\",\n",
              "   'time': '3:17',\n",
              "   'visual_description': 'A blue banner appears with the text \"What quantization format to pick?\"'},\n",
              "  {'spoken_text': 'So the most common one is going to be Q4 quantization. So this is for four bit quantizations.',\n",
              "   'time': '3:23',\n",
              "   'visual_description': 'The webpage shows a table with different bit versions of the model, including 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit.'},\n",
              "  {'visual_description': 'The webpage shows a table with different bit versions of the model, including 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit.',\n",
              "   'spoken_text': \"So when you see the Q and whatever the number is, that tells you whether it\\\\'s four bit, five bit, eight bit etcetera going through this.\",\n",
              "   'time': '3:30'},\n",
              "  {'spoken_text': \"Now if you\\\\'re not sure which ones to pick, usually the best one you\\\\'re going to go for to get the most performance or sort of bang for the buck is is going to be the Q4K models.\",\n",
              "   'time': '3:37',\n",
              "   'visual_description': 'The webpage shows a table with different bit versions of the model, including 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit.'},\n",
              "  {'visual_description': 'The webpage shows a table with different bit versions of the model, including 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit.',\n",
              "   'time': '3:48',\n",
              "   'spoken_text': \"And you\\\\'ll often see that after the K you\\\\'ll either have like an S for small, M for medium or L for large, which will change the the size of these.\"},\n",
              "  {'time': '3:58',\n",
              "   'spoken_text': \"So generally here you\\\\'re making some kind of trade off. Usually you\\\\'re going to be making a trade off between size of the model, speed of the model and quality of the model.\",\n",
              "   'visual_description': 'The webpage shows a table with different bit versions of the model, including 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit.'},\n",
              "  {'time': '4:08',\n",
              "   'spoken_text': 'So like I said before, people often find that the Q4K format tends to do really well for quality and is also not, you know, extremely slow.',\n",
              "   'visual_description': 'The webpage shows a table with different bit versions of the model, including 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit.'},\n",
              "  {'time': '4:20',\n",
              "   'visual_description': 'The webpage shows a table with different bit versions of the model, including 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit.',\n",
              "   'spoken_text': \"If you go to the Q8 models, again you\\\\'re perhaps getting a bit better quality, but you\\\\'re doing it at the cost of having a slower model there.\"},\n",
              "  {'time': '4:28',\n",
              "   'spoken_text': 'Now, how does the quality of the model change? It really is different from model to model.',\n",
              "   'visual_description': 'The webpage shows a picture of a llama in a jail cell.'},\n",
              "  {'visual_description': 'The webpage shows a model description with the text \"This is an uncensored version of the original Llama-3.2-3B-Instruct, created using mlabonne\\\\\\'s script, which builds on FailSpy\\\\\\'s notebook and the original work from Andy Arditi et al. The method is discussed in details in this blog and this paper.\"',\n",
              "   'spoken_text': \"In the past we used to sort of look at this as like the lower the precision probably meant that it wouldn\\\\'t be able to do certain kind of tasks like function calling, like anything sort of related to reasoning in inverted commas etcetera.\",\n",
              "   'time': '4:34'},\n",
              "  {'spoken_text': 'Nowadays, you know, my attitude about this has changed. I really kind of feel that you need to try it out from model to model. It can change quite a lot.',\n",
              "   'visual_description': 'The webpage shows a model description with the text \"Examples\" and a list of prompts and responses.',\n",
              "   'time': '4:48'},\n",
              "  {'time': '4:57',\n",
              "   'visual_description': 'The webpage shows a model description with the text \"Usage\" and a code snippet.',\n",
              "   'spoken_text': \"If you want a model that\\\\'s just super fast and just good at say chatting or something and you don\\\\'t really care about any sort of higher level kind of stuff, often you can get away with a Q2 model.\"},\n",
              "  {'time': '5:09',\n",
              "   'spoken_text': 'So basically using a two bit quantized model like I showed before downloading.',\n",
              "   'visual_description': 'The webpage shows a model description with the text \"vLLM serving\" and a code snippet.'},\n",
              "  {'time': '5:13',\n",
              "   'spoken_text': \"Now obviously that\\\\'s going to be a much smaller model than the other higher bit rate models in there.\",\n",
              "   'visual_description': 'The webpage shows a model description with the text \"Custom Chat Template and Parameters\" and a code snippet.'},\n",
              "  {'visual_description': 'The webpage shows a model description with the text \"Custom Chat Template and Parameters\" and a code snippet.',\n",
              "   'time': '5:20',\n",
              "   'spoken_text': 'You can also do things like make your own model file just like normal and basically just put from hf.co and then the model name in there.'},\n",
              "  {'time': '5:30',\n",
              "   'visual_description': 'The webpage shows a model description with the text \"Custom Chat Template and Parameters\" and a code snippet.',\n",
              "   'spoken_text': 'And of course in that model file you could put hard coded system prompt if you want to do that.'},\n",
              "  {'time': '5:36',\n",
              "   'spoken_text': 'You can see we can also change the chat template if you want to.',\n",
              "   'visual_description': 'The webpage shows a model description with the text \"Custom Chat Template and Parameters\" and a code snippet.'},\n",
              "  {'visual_description': 'The webpage shows a model description with the text \"Custom Chat Template and Parameters\" and a code snippet.',\n",
              "   'time': '5:40',\n",
              "   'spoken_text': 'Now, it needs to be in this Jinja or double handle bars kind of format for doing this.'},\n",
              "  {'spoken_text': \"And occasionally you will find that some of the GGGFs don\\\\'t have this set properly and in that case you need to come in and set it yourself.\",\n",
              "   'time': '5:45',\n",
              "   'visual_description': 'The webpage shows a model description with the text \"Custom Quantization\" and a code snippet.'},\n",
              "  {'visual_description': 'The webpage shows a model description with the text \"Use Ollama with any GGGF Model on Hugging Face Hub\" and a code snippet.',\n",
              "   'spoken_text': \"But for most of the files you\\\\'re going to be fine just out of the box, just being able to search for models that you can basically find the GGGF version and then download it in here.\",\n",
              "   'time': '5:54'},\n",
              "  {'time': '6:06',\n",
              "   'spoken_text': \"And so there\\\\'s a lot of these models in here going right back to the old ones from the bloke through to a lot of the more sort of exotic fine tunes of the llama models, of the Mistral models, the Gemma models.\",\n",
              "   'visual_description': 'The webpage shows a list of models with the text \"llama gguf\" in the search bar.'},\n",
              "  {'time': '6:20',\n",
              "   'spoken_text': \"Even the Gwen 2.5 models, you\\\\'ll see that they themselves have GGGF versions and other people have done conversions of their models to GGGF as well.\",\n",
              "   'visual_description': 'The webpage shows a list of models with the text \"llama gguf\" in the search bar.'},\n",
              "  {'visual_description': 'The webpage shows a list of models with the text \"llama gguf\" in the search bar.',\n",
              "   'time': '6:34',\n",
              "   'spoken_text': \"So this gives you a lot of models that you can start using with Ollama and don\\\\'t forget as always you can set up the Ollama to have the same kind of endpoint as an Open AI endpoint to use it if you wanted to do something like with swarm or to do other things where people are using these sort of standard Open AI endpoint in there.\"},\n",
              "  {'spoken_text': \"All right, I\\\\'m going to do another video about Ollama and we\\\\'re going to look at how we can actually put this in in the cloud and serve it with a GPU in the cloud for this kind of thing.\",\n",
              "   'time': '6:58',\n",
              "   'visual_description': 'The webpage shows a list of models with the text \"llama gguf\" in the search bar.'},\n",
              "  {'spoken_text': 'But until then I just wanted to show you that this is a really cool feature that has now come to Ollama and it gives you just access to so many other models so quickly and just simplifies before you used to have to bring this down yourself, do all the setup yourself.',\n",
              "   'visual_description': 'The webpage shows a browser window with the text \"bartowski/Llama-3.2-1B-Instruct-GGUF\" and a list of files.',\n",
              "   'time': '7:09'},\n",
              "  {'time': '7:20',\n",
              "   'spoken_text': 'Now this is something that you can just do out of the box, get it working simply and quickly.',\n",
              "   'visual_description': 'The webpage shows a browser window with the text \"bartowski/Llama-3.2-1B-Instruct-GGUF\" and a dropdown menu with different quantization options.'},\n",
              "  {'spoken_text': \"All right, as always, if you\\\\'ve got any questions, please put them in the comments below.\",\n",
              "   'time': '7:31',\n",
              "   'visual_description': 'A blue screen with a circuit board pattern and a thumbs up icon, a subscribe button, and a bell icon.'},\n",
              "  {'time': '7:35',\n",
              "   'visual_description': 'A blue screen with a circuit board pattern and a thumbs up icon, a subscribe button, and a bell icon.',\n",
              "   'spoken_text': 'If you like this video and you want to see more videos like this, please click like and subscribe.'},\n",
              "  {'spoken_text': \"You\\\\'ll see these videos as they come out more often and I will talk to you in the next video. Bye for now.\",\n",
              "   'visual_description': 'A blue screen with a circuit board pattern and a thumbs up icon, a subscribe button, and a bell icon. The screen then transitions to a white circle with a YouTube logo inside of it.',\n",
              "   'time': '7:41'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_tools\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XzWHXh7E-TG",
        "outputId": "4a8d6d7e-7273-45a4-aaef-ad4e592e1dba"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tool(function_declarations=[FunctionDeclaration(response=None, description='Set the timecodes for the video with associated text', name='set_timecodes', parameters=Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='OBJECT', description=None, enum=None, format=None, items=None, properties={'timecodes': Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='ARRAY', description=None, enum=None, format=None, items=Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='OBJECT', description=None, enum=None, format=None, items=None, properties={'time': Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='STRING', description=None, enum=None, format=None, items=None, properties=None, required=None), 'text': Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='STRING', description=None, enum=None, format=None, items=None, properties=None, required=None)}, required=['time', 'text']), properties=None, required=None)}, required=['timecodes'])), FunctionDeclaration(response=None, description='Set the timecodes for the video with associated text and object list', name='set_timecodes_with_objects', parameters=Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='OBJECT', description=None, enum=None, format=None, items=None, properties={'timecodes': Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='ARRAY', description=None, enum=None, format=None, items=Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='OBJECT', description=None, enum=None, format=None, items=None, properties={'time': Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='STRING', description=None, enum=None, format=None, items=None, properties=None, required=None), 'text': Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='STRING', description=None, enum=None, format=None, items=None, properties=None, required=None), 'objects': Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='ARRAY', description=None, enum=None, format=None, items=Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='STRING', description=None, enum=None, format=None, items=None, properties=None, required=None), properties=None, required=None)}, required=['time', 'text', 'objects']), properties=None, required=None)}, required=['timecodes'])), FunctionDeclaration(response=None, description='Set the timecodes for the video with associated numeric values', name='set_timecodes_with_numeric_values', parameters=Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='OBJECT', description=None, enum=None, format=None, items=None, properties={'timecodes': Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='ARRAY', description=None, enum=None, format=None, items=Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='OBJECT', description=None, enum=None, format=None, items=None, properties={'time': Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='STRING', description=None, enum=None, format=None, items=None, properties=None, required=None), 'value': Schema(min_items=None, example=None, property_ordering=None, pattern=None, minimum=None, default=None, any_of=None, max_length=None, title=None, min_length=None, min_properties=None, max_items=None, maximum=None, nullable=None, max_properties=None, type='NUMBER', description=None, enum=None, format=None, items=None, properties=None, required=None)}, required=['time', 'value']), properties=None, required=None)}, required=['timecodes']))], retrieval=None, google_search=None, google_search_retrieval=None, code_execution=None)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}